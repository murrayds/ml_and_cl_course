{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dakota Murray\n",
    "## Applying ML to CL\n",
    "### Assignment 2 Part 2\n",
    "\n",
    "In this assignment, I chose to attempt to classify the Switchboard Dialogue Act Corpus into three categories: \"question\", \"answer\", and \"statement\". I manually aggregated dialogue acts into one of three categories, though some dialogue acts did not fit easily onto one, and as such were classifeid into \"other\" and were removed from further training/testing. \n",
    "\n",
    "The only features that I used for this classifier were the stemmed tokens from the utterance itself. Becuse utterances were short, I chose not to use parts-of-speech tagged tokens, as this would have made the resulting feature space much too sparse. Accuracy would likely be improved if additional features were included, such as the length of the utterance, its index in the transcript, and the characteristics of the speaker (education, sex, etc.), but I do not include these features here. \n",
    "\n",
    "Once the features are vectorized (using a basic bag-of-words model), the training and evaluation process follow that of the parts-of-speech tagger almost identically. \n",
    "\n",
    "The final accuracy is about 93%, which seems fairly good. However, examining the confusion matrix, its clear from the confuion matrix that this is perhaps misleadingâ€“the vast majority of labels are under the \"statement\" category, so the accuracy is dominated by performance on this one category. Still, such a classifeir could prove useful for high-level classification of dialogue acts, and with some more tweaking (both of the categories and of the features) I see no reason why this cannot perform better. \n",
    "\n",
    "I am using a slightly different version of the Switchboard corpus code which works better with python 3. This code is stored on the github page linked below,\n",
    "\n",
    "https://github.com/cgpotts/swda\n",
    "\n",
    "\n",
    "This first bit of code below defines some helper functions for use elsewhere in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_to_simple_tag(tag):\n",
    "    \"\"\"\n",
    "    This fuction takes as input a single tag as that defined for the Switchboard \n",
    "    Dialogue Act corpus, and returns the custom aggregated label\n",
    "    \"\"\"\n",
    "    if tag in ['^g', 'qh', 'qo', 'bh', 'qy^d', 'qw', 'qy', '^g', 'qw^d']:\n",
    "        return('question')\n",
    "    elif tag in ['aa', 'ny', 'nn', 'na', '^h', 'ng', 'no', 'arp_nd', 'ar', 'aap_am']:\n",
    "        return('answer')\n",
    "    elif tag in ['sd', 'sv', 'ba', 'fc', 'bk', 'h', 'fo_o_fw_by_bc', '^q', 'bf', 'ad', 'b^m', 'br', 'fp', 'qrr', 'oo_co_cc', 'fa', 'ft']:\n",
    "        return('statement')\n",
    "    else:\n",
    "        return('other')\n",
    "    \n",
    "\n",
    "def corpus_to_data(utterances):\n",
    "    \"\"\"\n",
    "    Iterates through the utterances and builds the feature and label sets\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "\n",
    "    for utt in utterances:\n",
    "        tag = full_to_simple_tag(utt.act_tag)\n",
    "        if tag != \"other\":\n",
    "            X.append(utt.text)\n",
    "            y.append(tag)\n",
    "        \n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the functions that came along with the Switchboard Dialogue Act corpus in order to load the data and create a list of utterances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transcript 1155\n"
     ]
    }
   ],
   "source": [
    "from swda import CorpusReader\n",
    "corpus = CorpusReader('swda')\n",
    "\n",
    "utterances = []\n",
    "# consider Question, Answer, or Statement\n",
    "for trans in corpus.iter_transcripts():\n",
    "    for utt in trans.utterances:\n",
    "        utterances.append(utt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the utterances loaded, I then use the helper functions I creaed in the first cell in order to construct the training, testing, and valiation corpuses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_cutoff = int(.80 * len(utterances)) \n",
    "training_utt = utterances[:train_test_cutoff]\n",
    "testing_utt = utterances[train_test_cutoff:]\n",
    "\n",
    "train_val_cutoff = int(.25 * len(training_utt))\n",
    "validation_utt = training_utt[:train_val_cutoff]\n",
    "training_utt = training_utt[train_val_cutoff:]\n",
    "\n",
    "# Build the feature sets for each partition\n",
    "X_train, y_train = corpus_to_data(training_utt)\n",
    "X_test, y_test = corpus_to_data(testing_utt)\n",
    "X_val, y_val = corpus_to_data(testing_utt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas I used the dictionary vectorizer for the parts of speech tagger, here I instead use a Count Vectorizer, which simply tokenizes a sentence, stems the tokens, and counts them. The result is a simple bag-of-words model. As before, I train the vectorizer on all teh training data in order to create a common features space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we need to vectorize our inputs...\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "stemmer = EnglishStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "\n",
    "# Fit our DictVectorizer with our set of features\n",
    "dict_vectorizer = CountVectorizer(analyzer=stemmed_words)\n",
    "\n",
    "dict_vectorizer.fit(X_train + X_test + X_val)\n",
    "\n",
    "# Convert dict features to vectors\n",
    "X_train = dict_vectorizer.transform(X_train)\n",
    "X_test = dict_vectorizer.transform(X_test)\n",
    "X_val = dict_vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, I encode the labels using the sklearn LabelEncoder package. This code is identical to the parts-of-speech tagger. I also use the np_utils functions from the Keras library in order to convert the label vecors into the categoricals expected by the Keras Classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Now we encode ouor output vector, y\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fit LabelEncoder with our list of classes\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train + y_test + y_val)\n",
    "\n",
    "# Encode class values as integers\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "\n",
    "# Convert integers to dummy variables (one hot encoded)\n",
    "# Use keras module to make it happen\n",
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "y_val = np_utils.to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, I now use the same exact Keras setup as before. I reduce the number of neurons somewhat, as this is a less complex problem. I again use a `relu` activation, and again use sogtmax to produce the final bounded output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "def build_model(input_dim, hidden_neurons, output_dim):\n",
    "    \"\"\"\n",
    "    This function takes a set of arguments as input and outputs the compuled \n",
    "    (but not trained) Keras model. \n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(hidden_neurons, input_dim=input_dim),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.40),\n",
    "        Dense(hidden_neurons),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.40),\n",
    "        Dense(output_dim, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model_params = {\n",
    "    'build_fn': build_model,\n",
    "    'input_dim': X_train.shape[1],\n",
    "    'hidden_neurons': 256,\n",
    "    'output_dim': y_train.shape[1],\n",
    "    'epochs': 5,\n",
    "    'batch_size': 128,\n",
    "    'verbose': 1,\n",
    "    'validation_data': (X_val, y_val),\n",
    "    'shuffle': True\n",
    "}\n",
    "\n",
    "clf = KerasClassifier(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I train the model using the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dakotamurray/miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/dakotamurray/miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/dakotamurray/miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 81755 samples, validate on 27391 samples\n",
      "Epoch 1/5\n",
      "81755/81755 [==============================] - 37s 455us/step - loss: 0.3011 - acc: 0.9048 - val_loss: 0.2548 - val_acc: 0.9227\n",
      "Epoch 2/5\n",
      "81755/81755 [==============================] - 35s 434us/step - loss: 0.2317 - acc: 0.9267 - val_loss: 0.2456 - val_acc: 0.9271\n",
      "Epoch 3/5\n",
      "81755/81755 [==============================] - 37s 449us/step - loss: 0.2038 - acc: 0.9341 - val_loss: 0.2448 - val_acc: 0.9298\n",
      "Epoch 4/5\n",
      "81755/81755 [==============================] - 36s 443us/step - loss: 0.1817 - acc: 0.9402 - val_loss: 0.2647 - val_acc: 0.9288\n",
      "Epoch 5/5\n",
      "81755/81755 [==============================] - 37s 455us/step - loss: 0.1612 - acc: 0.9459 - val_loss: 0.2734 - val_acc: 0.9288\n"
     ]
    }
   ],
   "source": [
    "hist = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I produce a raw accuracy score of the data. We get a reasonable score of 93 percent, which seems pretty good for a natural language classification with short utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27391/27391 [==============================] - 2s 79us/step\n",
      "0.9288087328824864\n"
     ]
    }
   ],
   "source": [
    "score = clf.score(X_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, upon closer look at the classification, we see that much of this accuracy comes from classification of the \"statemenet\" instancesâ€”as these comprised the majority of the dataset. Indeex, a classifier that always returned \"statemenet\" would also have pretty good prformance. Still, the other categories had more correct than incorrect assignments and the classifier did better than chanceâ€”I would still call this successful, though more tweaking and work could definintely improve it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27391/27391 [==============================] - 2s 78us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3228,    11,   586],\n",
       "       [   49,   942,   842],\n",
       "       [  295,   167, 21271]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = clf.predict(X_test)\n",
    "confusion_matrix(y_test.argmax(axis=1), y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
